{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass 1 MNIST classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3QgC18a-_X1",
        "colab_type": "text"
      },
      "source": [
        "Load the Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn88I8i2Fd3y",
        "colab_type": "code",
        "outputId": "e28d46d0-cec8-40cd-da3e-608a3b85d472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import sys,numpy as np\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXAh28jZC9Jm",
        "colab_type": "code",
        "outputId": "7be7bc68-ba30-4534-870a-1750b0e66c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(np.array([1,3,4]) < np.array([4,6,3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMtip2rQ_GfW",
        "colab_type": "text"
      },
      "source": [
        "Load the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leJGAQxRFtTE",
        "colab_type": "code",
        "outputId": "10645e79-f566-4b55-d94e-4c1221f332c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(xtrain,ytrain),(xtest,ytest)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5pmNUSRGBO4",
        "colab_type": "code",
        "outputId": "dfc30573-d645-439f-9370-3932627dc568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiOnUhbG_KJW",
        "colab_type": "text"
      },
      "source": [
        "Convert the images of size 28*28 into single array of 784 values. This is called as straightening. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFAmGG65GKwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images=xtrain[0:60000].reshape(60000,28*28)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDoI8t92GeyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=ytrain[0:60000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt_EyKMUTDt0",
        "colab_type": "code",
        "outputId": "7b5d1e66-c847-45f9-e5a8-043fdbb2692c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqfXYpInAooP",
        "colab_type": "text"
      },
      "source": [
        "Convert the categorical labels values to numeric values using one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3G-3dHxGsYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_labels=np.zeros((len(labels),10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSqg8WeaHot-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l]=1\n",
        "\n",
        "labels=one_hot_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMgHQAevBOIw",
        "colab_type": "text"
      },
      "source": [
        "Reshape the testdata and hot encode the test labels data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNWYBKM9H-3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testimages=xtest.reshape(len(xtest),28*28)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIZVq54mIINb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testlabels=np.zeros((len(ytest),10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTVK6gDUIUY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,l in enumerate(ytest):\n",
        "  testlabels[i][l]=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zynoW2voIsAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOVob8EDBVDt",
        "colab_type": "text"
      },
      "source": [
        "Function to return the Relu value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMRbDWCwIw_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "    return (x>=0)*x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTsczy23Ba_1",
        "colab_type": "text"
      },
      "source": [
        "Function to return the derivative of Relu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6OrBLtdI4PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu2deriv(output):\n",
        "    return output>=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrFvy5hQBrbe",
        "colab_type": "text"
      },
      "source": [
        "Define the learning rate, no. of iterations, hidden layer size, no of labels in the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh7rLWUpJBr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha=0.001\n",
        "iterations=10\n",
        "hidden_size1=100\n",
        "pixels=784\n",
        "num_labels=10\n",
        "hidden_size2=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnUFMtETB6mE",
        "colab_type": "text"
      },
      "source": [
        "Set the batch size for mini batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT_I70_HhBgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gau3ReZiB_tV",
        "colab_type": "text"
      },
      "source": [
        "Initialise the weights for 0 to 1 layer with random values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-tJQWCaKIkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_0_1=0.2*np.random.random((pixels,hidden_size1))-0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFP1va_pCIxd",
        "colab_type": "text"
      },
      "source": [
        "Initialise the weights for 1 to 2 and 2 to 3 layers with random values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjHnCFHgKb8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_1_2=0.2*np.random.random((hidden_size1,hidden_size2))-0.1\n",
        "weights_2_3=0.2*np.random.random((hidden_size2,num_labels))-0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BLehJ9PpQZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7af6xcqApc1v",
        "colab_type": "code",
        "outputId": "416824a5-ea34-4632-c312-8488d41a6966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "#datagen.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-80cd93666eaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n\u001b[0;32m--> 929\u001b[0;31m                              'Got array with shape: ' + str(x.shape))\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (60000, 28, 28)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuaYe8x5CRj-",
        "colab_type": "text"
      },
      "source": [
        "Algorithm to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_K_eRakK6QN",
        "colab_type": "code",
        "outputId": "6a9d339e-f586-4e96-c000-46bb2bcda467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#Iteratively carry out the forward and back propagation\n",
        "for j in range(iterations):\n",
        "  error,correct_cnt=(0.0,0)\n",
        "\n",
        "  #Carry out mini batch gradient descent. Calculate the batches and iterate over it.\n",
        "  for i in range(int(len(images)/batchsize)):\n",
        "\n",
        "    #Calculate the batch start and end value to fetch to those images.\n",
        "    batchstart,batchend=((i*batchsize),((i+1)*batchsize))\n",
        "\n",
        "    #Select the first layer as the images from the batch size.\n",
        "    layer_0=images[batchstart:batchend]\n",
        "\n",
        "    #Create the first layer by multiplying the imput layer with the weights and passing it through Relu activation function. \n",
        "    layer_1=relu(np.dot(layer_0,weights_0_1))\n",
        "\n",
        "    #Drop few neurons from the layers to avoid overfitting the model\n",
        "    dropout_mask=np.random.randint(2,size=layer_1.shape)\n",
        "    layer_1*=dropout_mask*2\n",
        "\n",
        "    #Create the second layer by multiplying layer 1 with its input layer's weights\n",
        "    layer_2=np.dot(layer_1,weights_1_2)\n",
        "\n",
        "    #Create the third layer by multiplying layer 2 with its input layer's weights\n",
        "    layer_3=np.dot(layer_2,weights_2_3)\n",
        "\n",
        "    #Calculate the error by finding the difference between training final layer data and the calculated final layer data\n",
        "    error+=np.sum((labels[batchstart:batchend]-layer_3)**2)\n",
        "\n",
        "    #Conduct the backpropagation\n",
        "    for k in range(batchsize):\n",
        "\n",
        "      correct_cnt+=int(np.argmax(layer_3[k:k+1])==np.argmax(labels[batchstart+k:batchstart+k+1]))\n",
        "\n",
        "      #Calculate the third layer delta by taking the difference of expected and actual output\n",
        "      layer_3_delta=(labels[batchstart:batchend]-layer_3)/batchsize\n",
        "\n",
        "      #Calculate the second layer delta by multiplying the third layer delta and weights from second layer\n",
        "      layer_2_delta=layer_3_delta.dot(weights_2_3.T)\n",
        "\n",
        "      #Calculate the second layer delta by multiplying the third layer delta and weights from second layer and its Relu derivative. \n",
        "      #As Relu is applied on this layer.\n",
        "      layer_1_delta=layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
        "\n",
        "      #Update the weight values\n",
        "      weights_2_3+=alpha*layer_2.T.dot(layer_3_delta)\n",
        "      weights_1_2+=alpha*layer_1.T.dot(layer_2_delta)\n",
        "      weights_0_1+=alpha*layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "\n",
        "  #Print the ratio of error and correct values for every iteration\n",
        "  print(\"I\"+str(j))\n",
        "  print(\"Error \"+str(error/float(len(images)))[0:5])\n",
        "  print(\"Correct \"+str(correct_cnt/float(len(images))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0\n",
            "Error 0.549\n",
            "Correct 0.6986166666666667\n",
            "I1\n",
            "Error 0.451\n",
            "Correct 0.7779333333333334\n",
            "I2\n",
            "Error 0.427\n",
            "Correct 0.7961333333333334\n",
            "I3\n",
            "Error 0.418\n",
            "Correct 0.802\n",
            "I4\n",
            "Error 0.411\n",
            "Correct 0.8077833333333333\n",
            "I5\n",
            "Error 0.409\n",
            "Correct 0.8099\n",
            "I6\n",
            "Error 0.409\n",
            "Correct 0.8116333333333333\n",
            "I7\n",
            "Error 0.408\n",
            "Correct 0.813\n",
            "I8\n",
            "Error 0.408\n",
            "Correct 0.8113\n",
            "I9\n",
            "Error 0.409\n",
            "Correct 0.8113666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bDXJH3EGAst",
        "colab_type": "text"
      },
      "source": [
        "Function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EjUjQhDYcyH",
        "colab_type": "code",
        "outputId": "d064fc81-1dcd-4de3-b997-fc787d0732d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "if(j%10==0 or j==iterations-1):\n",
        "  error,correct_cnt=(0.0,0)\n",
        "\n",
        "  #For the test images as the input, apply the calculated weight values during the training phase to find the labels of the images.\n",
        "  for i in range(len(testimages)):\n",
        "\n",
        "    layer_0=testimages[i:i+1]\n",
        "    layer_1=relu(np.dot(layer_0,weights_0_1))\n",
        "    layer_2=np.dot(layer_1,weights_1_2)\n",
        "    layer_3=np.dot(layer_2,weights_2_3)\n",
        "\n",
        "    #Calculate the difference between the expected and actual values. Calculate the error and correct values predicted.\n",
        "    error+=np.sum((testlabels[i:i+1]-layer_3)**2)\n",
        "    correct_cnt+=int(np.argmax(layer_3)==np.argmax(testlabels[i:i+1]))\n",
        "    \n",
        "\n",
        "\n",
        "print(\"shape\",testlabels.shape)\n",
        "print(\"shape\",layer_3.shape)\n",
        "print(\"Error \"+str(error/float(len(testimages)))[0:5])\n",
        "print(\"Correct \"+str(correct_cnt/float(len(testimages))))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape (10000, 10)\n",
            "shape (1, 10)\n",
            "Error 0.314\n",
            "Correct 0.8575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96V0Qe4ImBdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Ki2rn0C7tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
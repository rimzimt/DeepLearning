{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","provenance":[],"authorship_tag":"ABX9TyOK4RHcqUQbztxDuTcHuOFQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Oa6WjjzxLQaD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c5b5b4b6-7ddc-454a-edec-3d6549dbe4d1","executionInfo":{"status":"ok","timestamp":1588890903470,"user_tz":420,"elapsed":2271,"user":{"displayName":"Rimzim Thube","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLsluMvnDGN7UrXPCRHxQJCJ4691H4hD0GwCBw=s64","userId":"15821276931952451987"}}},"source":["from __future__ import print_function\n","\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k30n3BOcRxqN","colab_type":"code","colab":{}},"source":["batch_size = 64  \n","epochs = 100  \n","samples = 10000  \n","path = 'fra.txt'\n","latent_dim = 256  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dv-ZfsvnR6FG","colab_type":"code","colab":{}},"source":["inputtexts = []\n","targettexts = []\n","inputchars = set()\n","targetchars = set()\n","with open(path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(samples, len(lines) - 1)]:\n","    inputtext, targettext, _ = line.split('\\t')\n","    \n","    targettext = '\\t' + targettext + '\\n'\n","    inputtexts.append(inputtext)\n","    targettexts.append(targettext)\n","    for char in inputtext:\n","        if char not in inputchars:\n","            inputchars.add(char)\n","    for char in targettext:\n","        if char not in targetchars:\n","            targetchars.add(char)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Mm0QnSeSQ1a","colab_type":"code","colab":{}},"source":["inputchars = sorted(list(inputchars))\n","targetchars = sorted(list(targetchars))\n","encodertokens = len(inputchars)\n","decodertokens = len(targetchars)\n","encoderseqlen = max([len(txt) for txt in inputtexts])\n","decoderseqlen = max([len(txt) for txt in targettexts])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Psw_b3SqSRQR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"c0fe1fd9-9488-4b15-8649-b8483bec0252","executionInfo":{"status":"ok","timestamp":1588891038342,"user_tz":420,"elapsed":445,"user":{"displayName":"Rimzim Thube","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLsluMvnDGN7UrXPCRHxQJCJ4691H4hD0GwCBw=s64","userId":"15821276931952451987"}}},"source":["print('No of samples:', len(inputtexts))\n","print('No of unique input tokens:', encodertokens)\n","print('No of unique output tokens:', decodertokens)\n","print('Max seq len for inputs:', encoderseqlen)\n","print('Max seq len for outputs:', decoderseqlen)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["No of samples: 10000\n","No of unique input tokens: 71\n","No of unique output tokens: 93\n","Max seq len for inputs: 16\n","Max seq len for outputs: 59\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QeQoIpQbSTCQ","colab_type":"code","colab":{}},"source":["inputtokenindex = dict(\n","    [(char, i) for i, char in enumerate(inputchars)])\n","targettokenindex = dict(\n","    [(char, i) for i, char in enumerate(targetchars)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oHgC3h0SU1s","colab_type":"code","colab":{}},"source":["encoderinputdata = np.zeros(\n","    (len(inputtexts), encoderseqlen, encodertokens),\n","    dtype='float32')\n","decoderinputdata = np.zeros(\n","    (len(inputtexts), decoderseqlen, decodertokens),\n","    dtype='float32')\n","decodertargetdata = np.zeros(\n","    (len(inputtexts), decoderseqlen, decodertokens),\n","    dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"42leT_PKSYNg","colab_type":"code","colab":{}},"source":["for i, (inputtext, targettext) in enumerate(zip(inputtexts, targettexts)):\n","    for t, char in enumerate(inputtext):\n","        encoderinputdata[i, t, inputtokenindex[char]] = 1.\n","    encoderinputdata[i, t + 1:, inputtokenindex[' ']] = 1.\n","    for t, char in enumerate(targettext):\n","        decoderinputdata[i, t, targettokenindex[char]] = 1.\n","        if t > 0:\n","            \n","            decodertargetdata[i, t - 1, targettokenindex[char]] = 1.\n","    decoderinputdata[i, t + 1:, targettokenindex[' ']] = 1.\n","    decodertargetdata[i, t:, targettokenindex[' ']] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJhtdcFbScqj","colab_type":"code","colab":{}},"source":["encoderinputs = Input(shape=(None, encodertokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoderinputs)\n","encoderstates = [state_h, state_c]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt2u8ijLShS2","colab_type":"code","colab":{}},"source":["decoderinputs = Input(shape=(None, decodertokens))\n","\n","decoderlstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoderoutputs, _, _ = decoderlstm(decoderinputs,\n","                                     initial_state=encoderstates)\n","decoderdense = Dense(decodertokens, activation='softmax')\n","decoderoutputs = decoderdense(decoderoutputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"luLCQFUeSwNK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"841eda1c-3919-4cc4-ea7e-a3881870490c","executionInfo":{"status":"ok","timestamp":1588892862375,"user_tz":420,"elapsed":1536035,"user":{"displayName":"Rimzim Thube","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLsluMvnDGN7UrXPCRHxQJCJ4691H4hD0GwCBw=s64","userId":"15821276931952451987"}}},"source":["\n","model = Model([encoderinputs, decoderinputs], decoderoutputs)\n","\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit([encoderinputdata, decoderinputdata],decodertargetdata, batch_size=batch_size,\n","          \n","          epochs=epochs,\n","          validation_split=0.2)\n","model.save('s2s.h5')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Train on 8000 samples, validate on 2000 samples\n","Epoch 1/100\n","8000/8000 [==============================] - 17s 2ms/step - loss: 1.1783 - accuracy: 0.7243 - val_loss: 1.0487 - val_accuracy: 0.7123\n","Epoch 2/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.8574 - accuracy: 0.7693 - val_loss: 0.8549 - val_accuracy: 0.7645\n","Epoch 3/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.6916 - accuracy: 0.8056 - val_loss: 0.7245 - val_accuracy: 0.7883\n","Epoch 4/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.6126 - accuracy: 0.8241 - val_loss: 0.6765 - val_accuracy: 0.8024\n","Epoch 5/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.5579 - accuracy: 0.8366 - val_loss: 0.6271 - val_accuracy: 0.8164\n","Epoch 6/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.5191 - accuracy: 0.8471 - val_loss: 0.5871 - val_accuracy: 0.8270\n","Epoch 7/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.4888 - accuracy: 0.8555 - val_loss: 0.5601 - val_accuracy: 0.8343\n","Epoch 8/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.4630 - accuracy: 0.8623 - val_loss: 0.5387 - val_accuracy: 0.8411\n","Epoch 9/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.4410 - accuracy: 0.8680 - val_loss: 0.5242 - val_accuracy: 0.8438\n","Epoch 10/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.4210 - accuracy: 0.8743 - val_loss: 0.5096 - val_accuracy: 0.8481\n","Epoch 11/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.4038 - accuracy: 0.8795 - val_loss: 0.4986 - val_accuracy: 0.8513\n","Epoch 12/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.3869 - accuracy: 0.8842 - val_loss: 0.4808 - val_accuracy: 0.8570\n","Epoch 13/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.3712 - accuracy: 0.8888 - val_loss: 0.4754 - val_accuracy: 0.8588\n","Epoch 14/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.3573 - accuracy: 0.8923 - val_loss: 0.4632 - val_accuracy: 0.8631\n","Epoch 15/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.3444 - accuracy: 0.8963 - val_loss: 0.4589 - val_accuracy: 0.8646\n","Epoch 16/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.3318 - accuracy: 0.8999 - val_loss: 0.4525 - val_accuracy: 0.8657\n","Epoch 17/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.3194 - accuracy: 0.9037 - val_loss: 0.4523 - val_accuracy: 0.8667\n","Epoch 18/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.3086 - accuracy: 0.9067 - val_loss: 0.4453 - val_accuracy: 0.8707\n","Epoch 19/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2981 - accuracy: 0.9101 - val_loss: 0.4414 - val_accuracy: 0.8711\n","Epoch 20/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2881 - accuracy: 0.9126 - val_loss: 0.4443 - val_accuracy: 0.8713\n","Epoch 21/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2785 - accuracy: 0.9156 - val_loss: 0.4394 - val_accuracy: 0.8721\n","Epoch 22/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2692 - accuracy: 0.9183 - val_loss: 0.4391 - val_accuracy: 0.8734\n","Epoch 23/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2600 - accuracy: 0.9212 - val_loss: 0.4404 - val_accuracy: 0.8739\n","Epoch 24/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.2517 - accuracy: 0.9235 - val_loss: 0.4392 - val_accuracy: 0.8742\n","Epoch 25/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2439 - accuracy: 0.9257 - val_loss: 0.4418 - val_accuracy: 0.8738\n","Epoch 26/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2356 - accuracy: 0.9282 - val_loss: 0.4385 - val_accuracy: 0.8755\n","Epoch 27/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2288 - accuracy: 0.9303 - val_loss: 0.4410 - val_accuracy: 0.8759\n","Epoch 28/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2209 - accuracy: 0.9328 - val_loss: 0.4470 - val_accuracy: 0.8759\n","Epoch 29/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2147 - accuracy: 0.9344 - val_loss: 0.4468 - val_accuracy: 0.8759\n","Epoch 30/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2080 - accuracy: 0.9363 - val_loss: 0.4505 - val_accuracy: 0.8763\n","Epoch 31/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.2017 - accuracy: 0.9382 - val_loss: 0.4479 - val_accuracy: 0.8771\n","Epoch 32/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1954 - accuracy: 0.9401 - val_loss: 0.4510 - val_accuracy: 0.8770\n","Epoch 33/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1898 - accuracy: 0.9415 - val_loss: 0.4546 - val_accuracy: 0.8773\n","Epoch 34/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1844 - accuracy: 0.9435 - val_loss: 0.4558 - val_accuracy: 0.8771\n","Epoch 35/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1789 - accuracy: 0.9453 - val_loss: 0.4648 - val_accuracy: 0.8760\n","Epoch 36/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1737 - accuracy: 0.9465 - val_loss: 0.4704 - val_accuracy: 0.8762\n","Epoch 37/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1690 - accuracy: 0.9478 - val_loss: 0.4694 - val_accuracy: 0.8768\n","Epoch 38/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1641 - accuracy: 0.9495 - val_loss: 0.4746 - val_accuracy: 0.8762\n","Epoch 39/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1596 - accuracy: 0.9509 - val_loss: 0.4801 - val_accuracy: 0.8761\n","Epoch 40/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1554 - accuracy: 0.9521 - val_loss: 0.4857 - val_accuracy: 0.8761\n","Epoch 41/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1509 - accuracy: 0.9535 - val_loss: 0.4858 - val_accuracy: 0.8768\n","Epoch 42/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1473 - accuracy: 0.9546 - val_loss: 0.4940 - val_accuracy: 0.8765\n","Epoch 43/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1431 - accuracy: 0.9558 - val_loss: 0.4944 - val_accuracy: 0.8772\n","Epoch 44/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.1393 - accuracy: 0.9569 - val_loss: 0.5049 - val_accuracy: 0.8771\n","Epoch 45/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1356 - accuracy: 0.9580 - val_loss: 0.5027 - val_accuracy: 0.8764\n","Epoch 46/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1326 - accuracy: 0.9590 - val_loss: 0.5119 - val_accuracy: 0.8765\n","Epoch 47/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1291 - accuracy: 0.9602 - val_loss: 0.5160 - val_accuracy: 0.8764\n","Epoch 48/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1261 - accuracy: 0.9609 - val_loss: 0.5231 - val_accuracy: 0.8759\n","Epoch 49/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1232 - accuracy: 0.9619 - val_loss: 0.5213 - val_accuracy: 0.8761\n","Epoch 50/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1200 - accuracy: 0.9630 - val_loss: 0.5281 - val_accuracy: 0.8761\n","Epoch 51/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.5326 - val_accuracy: 0.8756\n","Epoch 52/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1143 - accuracy: 0.9645 - val_loss: 0.5353 - val_accuracy: 0.8761\n","Epoch 53/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1119 - accuracy: 0.9652 - val_loss: 0.5380 - val_accuracy: 0.8768\n","Epoch 54/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1096 - accuracy: 0.9658 - val_loss: 0.5510 - val_accuracy: 0.8754\n","Epoch 55/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1072 - accuracy: 0.9665 - val_loss: 0.5494 - val_accuracy: 0.8754\n","Epoch 56/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1045 - accuracy: 0.9673 - val_loss: 0.5521 - val_accuracy: 0.8757\n","Epoch 57/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.1020 - accuracy: 0.9680 - val_loss: 0.5629 - val_accuracy: 0.8760\n","Epoch 58/100\n","8000/8000 [==============================] - 17s 2ms/step - loss: 0.1001 - accuracy: 0.9685 - val_loss: 0.5628 - val_accuracy: 0.8762\n","Epoch 59/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0981 - accuracy: 0.9690 - val_loss: 0.5660 - val_accuracy: 0.8755\n","Epoch 60/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0959 - accuracy: 0.9697 - val_loss: 0.5693 - val_accuracy: 0.8758\n","Epoch 61/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0939 - accuracy: 0.9703 - val_loss: 0.5759 - val_accuracy: 0.8749\n","Epoch 62/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0916 - accuracy: 0.9710 - val_loss: 0.5859 - val_accuracy: 0.8749\n","Epoch 63/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0900 - accuracy: 0.9716 - val_loss: 0.5802 - val_accuracy: 0.8757\n","Epoch 64/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0884 - accuracy: 0.9718 - val_loss: 0.5916 - val_accuracy: 0.8749\n","Epoch 65/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0866 - accuracy: 0.9724 - val_loss: 0.5993 - val_accuracy: 0.8746\n","Epoch 66/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0850 - accuracy: 0.9728 - val_loss: 0.5984 - val_accuracy: 0.8752\n","Epoch 67/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0829 - accuracy: 0.9735 - val_loss: 0.6012 - val_accuracy: 0.8749\n","Epoch 68/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0812 - accuracy: 0.9740 - val_loss: 0.6062 - val_accuracy: 0.8743\n","Epoch 69/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0798 - accuracy: 0.9744 - val_loss: 0.6086 - val_accuracy: 0.8750\n","Epoch 70/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0782 - accuracy: 0.9748 - val_loss: 0.6152 - val_accuracy: 0.8744\n","Epoch 71/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.6202 - val_accuracy: 0.8748\n","Epoch 72/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0753 - accuracy: 0.9755 - val_loss: 0.6190 - val_accuracy: 0.8741\n","Epoch 73/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0741 - accuracy: 0.9757 - val_loss: 0.6245 - val_accuracy: 0.8748\n","Epoch 74/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0725 - accuracy: 0.9763 - val_loss: 0.6275 - val_accuracy: 0.8752\n","Epoch 75/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.6366 - val_accuracy: 0.8748\n","Epoch 76/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0702 - accuracy: 0.9771 - val_loss: 0.6366 - val_accuracy: 0.8748\n","Epoch 77/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0688 - accuracy: 0.9776 - val_loss: 0.6401 - val_accuracy: 0.8744\n","Epoch 78/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.6438 - val_accuracy: 0.8743\n","Epoch 79/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0660 - accuracy: 0.9780 - val_loss: 0.6511 - val_accuracy: 0.8747\n","Epoch 80/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0650 - accuracy: 0.9786 - val_loss: 0.6543 - val_accuracy: 0.8747\n","Epoch 81/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0641 - accuracy: 0.9787 - val_loss: 0.6548 - val_accuracy: 0.8743\n","Epoch 82/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.6607 - val_accuracy: 0.8733\n","Epoch 83/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.6662 - val_accuracy: 0.8741\n","Epoch 84/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0611 - accuracy: 0.9793 - val_loss: 0.6665 - val_accuracy: 0.8736\n","Epoch 85/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.6666 - val_accuracy: 0.8741\n","Epoch 86/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0589 - accuracy: 0.9803 - val_loss: 0.6717 - val_accuracy: 0.8729\n","Epoch 87/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0577 - accuracy: 0.9805 - val_loss: 0.6776 - val_accuracy: 0.8733\n","Epoch 88/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.6822 - val_accuracy: 0.8729\n","Epoch 89/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.6845 - val_accuracy: 0.8730\n","Epoch 90/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0551 - accuracy: 0.9814 - val_loss: 0.6878 - val_accuracy: 0.8730\n","Epoch 91/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.6863 - val_accuracy: 0.8744\n","Epoch 92/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0533 - accuracy: 0.9818 - val_loss: 0.6884 - val_accuracy: 0.8737\n","Epoch 93/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0525 - accuracy: 0.9819 - val_loss: 0.7015 - val_accuracy: 0.8732\n","Epoch 94/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.6995 - val_accuracy: 0.8737\n","Epoch 95/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.6971 - val_accuracy: 0.8731\n","Epoch 96/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0502 - accuracy: 0.9828 - val_loss: 0.7067 - val_accuracy: 0.8729\n","Epoch 97/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 0.7108 - val_accuracy: 0.8726\n","Epoch 98/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.7098 - val_accuracy: 0.8726\n","Epoch 99/100\n","8000/8000 [==============================] - 15s 2ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.7152 - val_accuracy: 0.8729\n","Epoch 100/100\n","8000/8000 [==============================] - 16s 2ms/step - loss: 0.0473 - accuracy: 0.9834 - val_loss: 0.7217 - val_accuracy: 0.8720\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H1wRcL5TS-42","colab_type":"code","colab":{}},"source":["encodermodel = Model(encoderinputs, encoderstates)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOaVhgg4aCet","colab_type":"code","colab":{}},"source":["decoderstateinputh = Input(shape=(latent_dim,))\n","decoderstateinputc = Input(shape=(latent_dim,))\n","decoderstatesinputs = [decoderstateinputh, decoderstateinputc]\n","decoderoutputs, state_h, state_c = decoderlstm(\n","    decoderinputs, initial_state=decoderstatesinputs)\n","decoderstates = [state_h, state_c]\n","decoderoutputs = decoderdense(decoderoutputs)\n","decodermodel = Model(\n","    [decoderinputs] + decoderstatesinputs,\n","    [decoderoutputs] + decoderstates)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19Wo3nIpaE2a","colab_type":"code","colab":{}},"source":["\n","reverseinputcharindex = dict(\n","    (i, char) for char, i in inputtokenindex.items())\n","reversetargetcharindex = dict(\n","    (i, char) for char, i in targettokenindex.items())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NArjukjad52","colab_type":"code","colab":{}},"source":["def decodesequence(input_seq):\n","    statesvalue = encodermodel.predict(input_seq)\n","\n","    targetseq = np.zeros((1, 1, decodertokens))\n","    targetseq[0, 0, targettokenindex['\\t']] = 1.\n","\n","    stopcondition = False\n","    decodedsentence = ''\n","    while not stopcondition:\n","        outputtokens, h, c = decodermodel.predict(\n","            [targetseq] + statesvalue)\n","\n","        sampledtokenindex = np.argmax(outputtokens[0, -1, :])\n","        sampledchar = reversetargetcharindex[sampledtokenindex]\n","        decodedsentence += sampledchar\n","\n","\n","        if (sampledchar == '\\n' or\n","           len(decodedsentence) > decoderseqlen):\n","            stopcondition = True\n","\n","        targetseq = np.zeros((1, 1, decodertokens))\n","        targetseq[0, 0, sampledtokenindex] = 1.\n","\n","        statesvalue = [h, c]\n","        \n","    return decodedsentence\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtTV-ZdKayfg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8993e74a-ddab-440c-bca5-8926592f6241","executionInfo":{"status":"ok","timestamp":1588893331038,"user_tz":420,"elapsed":2842,"user":{"displayName":"Rimzim Thube","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLsluMvnDGN7UrXPCRHxQJCJ4691H4hD0GwCBw=s64","userId":"15821276931952451987"}}},"source":["for seq_index in range(100):\n","   \n","    input_seq = encoderinputdata[seq_index: seq_index + 1]\n","    decodedsentence = decodesequence(input_seq)\n","    print('-')\n","    print('Input sentence:', inputtexts[seq_index])\n","    print('Decoded sentence:', decodedsentence)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: Go.\n","Decoded sentence: Va !\n","\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut !\n","\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut !\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Cours !\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Cours !\n","\n","-\n","Input sentence: Who?\n","Decoded sentence: Qui ?\n","\n","-\n","Input sentence: Wow!\n","Decoded sentence: Ça alors !\n","\n","-\n","Input sentence: Fire!\n","Decoded sentence: Au feu !\n","\n","-\n","Input sentence: Help!\n","Decoded sentence: À l'aide !\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: Saute.\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Ça suffit !\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Ça suffit !\n","\n","-\n","Input sentence: Stop!\n","Decoded sentence: Ça suffit !\n","\n","-\n","Input sentence: Wait!\n","Decoded sentence: Attends !\n","\n","-\n","Input sentence: Wait!\n","Decoded sentence: Attends !\n","\n","-\n","Input sentence: Go on.\n","Decoded sentence: Poursuivez.\n","\n","-\n","Input sentence: Go on.\n","Decoded sentence: Poursuivez.\n","\n","-\n","Input sentence: Go on.\n","Decoded sentence: Poursuivez.\n","\n","-\n","Input sentence: Hello!\n","Decoded sentence: Bonjour !\n","\n","-\n","Input sentence: Hello!\n","Decoded sentence: Bonjour !\n","\n","-\n","Input sentence: I see.\n","Decoded sentence: Je comprends.\n","\n","-\n","Input sentence: I try.\n","Decoded sentence: J'essaye.\n","\n","-\n","Input sentence: I won!\n","Decoded sentence: Je l'ai emporté !\n","\n","-\n","Input sentence: I won!\n","Decoded sentence: Je l'ai emporté !\n","\n","-\n","Input sentence: I won.\n","Decoded sentence: J’ai gagné.\n","\n","-\n","Input sentence: Oh no!\n","Decoded sentence: Oh non !\n","\n","-\n","Input sentence: Attack!\n","Decoded sentence: Attaquez !\n","\n","-\n","Input sentence: Attack!\n","Decoded sentence: Attaquez !\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Merci !\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Merci !\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Merci !\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: Merci !\n","\n","-\n","Input sentence: Get up.\n","Decoded sentence: Lève-toi.\n","\n","-\n","Input sentence: Go now.\n","Decoded sentence: Vas-y maintenant.\n","\n","-\n","Input sentence: Go now.\n","Decoded sentence: Vas-y maintenant.\n","\n","-\n","Input sentence: Go now.\n","Decoded sentence: Vas-y maintenant.\n","\n","-\n","Input sentence: Got it!\n","Decoded sentence: Compris !\n","\n","-\n","Input sentence: Got it!\n","Decoded sentence: Compris !\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Pigé ?\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Pigé ?\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: Pigé ?\n","\n","-\n","Input sentence: Hop in.\n","Decoded sentence: Monte.\n","\n","-\n","Input sentence: Hop in.\n","Decoded sentence: Monte.\n","\n","-\n","Input sentence: Hug me.\n","Decoded sentence: Serrez-moi dans vos bras !\n","\n","-\n","Input sentence: Hug me.\n","Decoded sentence: Serrez-moi dans vos bras !\n","\n","-\n","Input sentence: I fell.\n","Decoded sentence: Je suis tombée.\n","\n","-\n","Input sentence: I fell.\n","Decoded sentence: Je suis tombée.\n","\n","-\n","Input sentence: I know.\n","Decoded sentence: Je sais.\n","\n","-\n","Input sentence: I left.\n","Decoded sentence: Je suis partie.\n","\n","-\n","Input sentence: I left.\n","Decoded sentence: Je suis partie.\n","\n","-\n","Input sentence: I lied.\n","Decoded sentence: J'aime Tom.\n","\n","-\n","Input sentence: I lost.\n","Decoded sentence: J'ai perdu.\n","\n","-\n","Input sentence: I paid.\n","Decoded sentence: J’ai payé.\n","\n","-\n","Input sentence: I'm 19.\n","Decoded sentence: J'ai trangé Tom.\n","\n","-\n","Input sentence: I'm OK.\n","Decoded sentence: Je vais bien.\n","\n","-\n","Input sentence: I'm OK.\n","Decoded sentence: Je vais bien.\n","\n","-\n","Input sentence: Listen.\n","Decoded sentence: Écoutez !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: No way!\n","Decoded sentence: C'est hors de question !\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Vraiment ?\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Vraiment ?\n","\n","-\n","Input sentence: Really?\n","Decoded sentence: Vraiment ?\n","\n","-\n","Input sentence: Thanks.\n","Decoded sentence: Merci !\n","\n","-\n","Input sentence: We try.\n","Decoded sentence: On essaye.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous avons gagné.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous avons gagné.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous avons gagné.\n","\n","-\n","Input sentence: We won.\n","Decoded sentence: Nous avons gagné.\n","\n","-\n","Input sentence: Ask Tom.\n","Decoded sentence: Demande à Tom.\n","\n","-\n","Input sentence: Awesome!\n","Decoded sentence: Fantastique !\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Soyez calme !\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Soyez calme !\n","\n","-\n","Input sentence: Be calm.\n","Decoded sentence: Soyez calme !\n","\n","-\n","Input sentence: Be cool.\n","Decoded sentence: Soyez calme !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be fair.\n","Decoded sentence: Soyez justes !\n","\n","-\n","Input sentence: Be kind.\n","Decoded sentence: Sois gentille!\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Be nice.\n","Decoded sentence: Soyez galmeste.\n","\n","-\n","Input sentence: Beat it.\n","Decoded sentence: Dégage !\n","\n","-\n","Input sentence: Call me.\n","Decoded sentence: Appellez-moi !\n","\n","-\n","Input sentence: Call me.\n","Decoded sentence: Appellez-moi !\n","\n","-\n","Input sentence: Call us.\n","Decoded sentence: Appelle-nous !\n","\n","-\n","Input sentence: Call us.\n","Decoded sentence: Appelle-nous !\n","\n","-\n","Input sentence: Come in.\n","Decoded sentence: Entre.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-sOP0kzMbCL-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}